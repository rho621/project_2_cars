{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from splinter import Browser\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.carmax.com/cars/all\"\n",
    "browser.visit(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2013 Honda\n",
      "2019 Chevrolet\n",
      "2012 Nissan\n",
      "2019 Ford\n",
      "2015 Honda\n",
      "2019 Ford\n",
      "2019 Chevrolet\n",
      "2012 Hyundai\n",
      "2013 Nissan\n",
      "2019 Ford\n",
      "2016 Toyota\n",
      "2013 Nissan\n",
      "2018 Chevrolet\n",
      "2018 Toyota\n",
      "2018 Chevrolet\n",
      "2018 Chevrolet\n",
      "2018 Chevrolet\n",
      "2019 GMC\n",
      "2016 Honda\n",
      "2019 GMC\n",
      "2018 Chevrolet\n",
      "2019 GMC\n",
      "2019 GMC\n",
      "2019 Dodge\n",
      "2013 Honda\n",
      "2019 Chevrolet\n",
      "2012 Nissan\n",
      "2019 Ford\n",
      "2015 Honda\n",
      "2019 Ford\n",
      "2019 Chevrolet\n",
      "2012 Hyundai\n",
      "2013 Nissan\n",
      "2019 Ford\n",
      "2016 Toyota\n",
      "2013 Nissan\n",
      "2018 Chevrolet\n",
      "2018 Toyota\n",
      "2018 Chevrolet\n",
      "2018 Chevrolet\n",
      "2018 Chevrolet\n",
      "2019 GMC\n",
      "2016 Honda\n",
      "2019 GMC\n",
      "2018 Chevrolet\n",
      "Odyssey EX\n",
      "Suburban 1500 LT\n",
      "Versa SL\n",
      "F250 Lariat\n",
      "Accord LX\n",
      "F150 Lariat\n",
      "Express 3500 LT\n",
      "Sonata GLS\n",
      "Altima S\n",
      "F150 XLT\n",
      "Camry SE\n",
      "Maxima SV\n",
      "Equinox LT\n",
      "Sienna XLE\n",
      "Colorado Z71\n",
      "Equinox LT\n",
      "Equinox LT\n",
      "Terrain SLE\n",
      "CR-V EX-L\n",
      "Acadia SLT\n",
      "Equinox LT\n",
      "Terrain SLT\n",
      "Terrain SLT\n",
      "Challenger R/T\n",
      "Odyssey EX\n",
      "Suburban 1500 LT\n",
      "Versa SL\n",
      "F250 Lariat\n",
      "Accord LX\n",
      "F150 Lariat\n",
      "Express 3500 LT\n",
      "Sonata GLS\n",
      "Altima S\n",
      "F150 XLT\n",
      "Camry SE\n",
      "Maxima SV\n",
      "Equinox LT\n",
      "Sienna XLE\n",
      "Colorado Z71\n",
      "Equinox LT\n",
      "Equinox LT\n",
      "Terrain SLE\n",
      "CR-V EX-L\n",
      "Acadia SLT\n",
      "Equinox LT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mikey\\Anaconda3\\lib\\site-packages\\splinter\\driver\\webdriver\\__init__.py:528: FutureWarning: browser.find_link_by_partial_text is deprecated. Use browser.links.find_by_partial_text instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping Complete\n",
      "2013 Honda\n",
      "2019 Chevrolet\n",
      "2012 Nissan\n",
      "2019 Ford\n",
      "2015 Honda\n",
      "2019 Ford\n",
      "2019 Chevrolet\n",
      "2012 Hyundai\n",
      "2013 Nissan\n",
      "2019 Ford\n",
      "2016 Toyota\n",
      "2013 Nissan\n",
      "2018 Chevrolet\n",
      "2018 Toyota\n",
      "2018 Chevrolet\n",
      "2018 Chevrolet\n",
      "2018 Chevrolet\n",
      "2019 GMC\n",
      "2016 Honda\n",
      "2019 GMC\n",
      "2018 Chevrolet\n",
      "2019 GMC\n",
      "2019 GMC\n",
      "2019 Dodge\n",
      "2013 Honda\n",
      "2019 Chevrolet\n",
      "2012 Nissan\n",
      "2019 Ford\n",
      "2015 Honda\n",
      "2019 Ford\n",
      "2019 Chevrolet\n",
      "2012 Hyundai\n",
      "2013 Nissan\n",
      "2019 Ford\n",
      "2016 Toyota\n",
      "2013 Nissan\n",
      "2018 Chevrolet\n",
      "2018 Toyota\n",
      "2018 Chevrolet\n",
      "2018 Chevrolet\n",
      "2018 Chevrolet\n",
      "2019 GMC\n",
      "2016 Honda\n",
      "2019 GMC\n",
      "2018 Chevrolet\n",
      "Odyssey EX\n",
      "Suburban 1500 LT\n",
      "Versa SL\n",
      "F250 Lariat\n",
      "Accord LX\n",
      "F150 Lariat\n",
      "Express 3500 LT\n",
      "Sonata GLS\n",
      "Altima S\n",
      "F150 XLT\n",
      "Camry SE\n",
      "Maxima SV\n",
      "Equinox LT\n",
      "Sienna XLE\n",
      "Colorado Z71\n",
      "Equinox LT\n",
      "Equinox LT\n",
      "Terrain SLE\n",
      "CR-V EX-L\n",
      "Acadia SLT\n",
      "Equinox LT\n",
      "Terrain SLT\n",
      "Terrain SLT\n",
      "Challenger R/T\n",
      "Odyssey EX\n",
      "Suburban 1500 LT\n",
      "Versa SL\n",
      "F250 Lariat\n",
      "Accord LX\n",
      "F150 Lariat\n",
      "Express 3500 LT\n",
      "Sonata GLS\n",
      "Altima S\n",
      "F150 XLT\n",
      "Camry SE\n",
      "Maxima SV\n",
      "Equinox LT\n",
      "Sienna XLE\n",
      "Colorado Z71\n",
      "Equinox LT\n",
      "Equinox LT\n",
      "Terrain SLE\n",
      "CR-V EX-L\n",
      "Acadia SLT\n",
      "Equinox LT\n",
      "Scraping Complete\n"
     ]
    }
   ],
   "source": [
    "for x in range (1, 3):\n",
    " \n",
    "#get model,year,make, price, location \n",
    "    \n",
    "    html= browser.html\n",
    "    soup = bs(html,'html.parser')\n",
    "    \n",
    "    year_make = soup.find_all('span', class_='year-make')\n",
    "    trim = soup.find_all('span', class_='model-trim')\n",
    "#price = \n",
    "\n",
    "    for result in year_make:\n",
    "    #need to separate year and make\n",
    "    \n",
    "        print(result.text)\n",
    "    \n",
    "    for model in trim:\n",
    "        print(model.text)\n",
    "    \n",
    "    try:\n",
    "        browser.click_link_by_partial_text('See More Matches')\n",
    "          \n",
    "    except:\n",
    "        print(\"Scraping Complete\")\n",
    "    \n",
    "    \n",
    "    \n",
    "#store all of these values into separate lists, combine into a data frame. find a way to make it more efficient?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
